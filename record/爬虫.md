- 用户，博文爬虫

  - 轮子

    https://github.com/dataabc/weibo-crawler

  - 轮子使用

    - config文件：修改参数，不爬取视频，不爬取转发博文，不写入数据库
    - user_id获取：手动精心挑选微博各个领域代表性人物的微博id，写入config文件
    - 运行py文件让他爬

  - 用户数据

    - 忘了从哪个网站拿到了大量的微博用户id，使用上述轮子，只爬取用户信息，不爬取博文

- 博文评论爬虫

  - 轮子

    https://github.com/Python3Spiders/WeiboSuperSpider

  - 轮子使用

    - 获取上述爬取博文的blog_id，添加到config文件
    - 运行weiboCommentScrapy.py 文件让他爬

- 数据处理

  - 爬取下来的数据格式均为csv文件，编写python脚本进行处理。

